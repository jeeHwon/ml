{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습 코드\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model_name = 'efficientnet-b0'  # b5\n",
    "\n",
    "image_size = EfficientNet.get_image_size(model_name)\n",
    "print(image_size)\n",
    "model = EfficientNet.from_pretrained(model_name, num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 로드\n",
    "batch_size  = 64\n",
    "random_seed = 555\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make dataset\n",
    "from torchvision import transforms, datasets\n",
    "data_path = 'data/ic/images'  # class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n",
    "ic_dataset = datasets.ImageFolder(\n",
    "                                data_path,\n",
    "                                transforms.Compose([\n",
    "                                    transforms.Resize((224, 224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "train_idx, tmp_idx = train_test_split(list(range(len(ic_dataset))), test_size=0.2, random_state=random_seed)\n",
    "datasets = {}\n",
    "datasets['train'] = Subset(ic_dataset, train_idx)\n",
    "tmp_dataset       = Subset(ic_dataset, tmp_idx)\n",
    "\n",
    "val_idx, test_idx = train_test_split(list(range(len(tmp_dataset))), test_size=0.5, random_state=random_seed)\n",
    "datasets['valid'] = Subset(tmp_dataset, val_idx)\n",
    "datasets['test']  = Subset(tmp_dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data loader 선언\n",
    "dataloaders, batch_num = {}, {}\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=4) \n",
    "dataloaders['valid'] = torch.utils.data.DataLoader(datasets['valid'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4) \n",
    "dataloaders['test']  = torch.utils.data.DataLoader(datasets['test'],\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=4) \n",
    "batch_num['train'], batch_num['valid'], batch_num['test'] = len(dataloaders['train']), len(dataloaders['valid']), len(dataloaders['test'])\n",
    "print('batch_size : %d,  tvt : %d / %d / %d' % (batch_size, batch_num['train'], batch_num['valid'], batch_num['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data check\n",
    "import torchvision\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "num_show_img = 5\n",
    "\n",
    "class_names = {\n",
    "    \"0\": \"apple_pie\",      \n",
    "    \"1\": \"baby_back_ribs\",   \n",
    "    \"2\": \"baklava\",   \n",
    "    \"3\": \"beef_carpaccio\", \n",
    "    \"4\": \"beef_tartare\",   \n",
    "    \"5\": \"beet_salad\",   \n",
    "    \"6\": \"beignets\",  \n",
    "    \"7\": \"bibimbap\",      \n",
    "    \"8\": \"bread_pudding\",   \n",
    "    \"9\": \"breakfast_burrito\",   \n",
    "\n",
    "    \"10\": \"bruschetta\", \n",
    "    \"11\": \"caesar_salad\",   \n",
    "    \"12\": \"cannoli\",   \n",
    "    \"13\": \"caprese_salad\",  \n",
    "    \"14\": \"carrot_cake\",      \n",
    "    \"15\": \"ceviche\",   \n",
    "    \"16\": \"cheese_plate\",   \n",
    "    \"17\": \"cheesecake\", \n",
    "    \"18\": \"chicken_curry\",   \n",
    "    \"19\": \"chicken_quesadilla\",   \n",
    "\n",
    "    \"20\": \"chicken_wings\",  \n",
    "    \"21\": \"chocolate_cake\",      \n",
    "    \"22\": \"chocolate_mousse\",   \n",
    "    \"23\": \"churros\",   \n",
    "    \"24\": \"clam_chowder\", \n",
    "    \"25\": \"club_sandwich\",   \n",
    "    \"26\": \"crab_cakes\",   \n",
    "    \"27\": \"creme_brulee\",  \n",
    "    \"28\": \"croque_madame\",      \n",
    "    \"29\": \"cup_cakes\",   \n",
    "\n",
    "    \"30\": \"deviled_eggs\",   \n",
    "    \"31\": \"donuts\", \n",
    "    \"32\": \"dumplings\",   \n",
    "    \"33\": \"edamame\",   \n",
    "    \"34\": \"eggs_benedict\",  \n",
    "    \"35\": \"escargots\",      \n",
    "    \"36\": \"falafel\",   \n",
    "    \"37\": \"filet_mignon\",   \n",
    "    \"38\": \"fish_and_chips\", \n",
    "    \"39\": \"foie_gras\",   \n",
    "\n",
    "    \"40\": \"french_fries\",   \n",
    "    \"41\": \"french_onion_soup\",   \n",
    "    \"42\": \"french_toast\", \n",
    "    \"43\": \"fried_calamari\",   \n",
    "    \"44\": \"fried_rice\",   \n",
    "    \"45\": \"frozen_yogurt\",   \n",
    "    \"46\": \"garlic_bread\", \n",
    "    \"47\": \"gnocchi\",   \n",
    "    \"48\": \"greek_salad\",   \n",
    "    \"49\": \"grilled_cheese_sandwich\"\n",
    "}\n",
    "\n",
    "# train check\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n",
    "imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n",
    "# valid check\n",
    "inputs, classes = next(iter(dataloaders['valid']))\n",
    "out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n",
    "imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])\n",
    "# test check\n",
    "inputs, classes = next(iter(dataloaders['test']))\n",
    "out = torchvision.utils.make_grid(inputs[:num_show_img])  # batch의 이미지를 오려부친다\n",
    "imshow(out, title=[class_names[str(int(x))] for x in classes[:num_show_img]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_loss, train_acc, valid_loss, valid_acc = [], [], [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                num_cnt += len(labels)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = float(running_loss / num_cnt)\n",
    "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                valid_loss.append(epoch_loss)\n",
    "                valid_acc.append(epoch_acc)\n",
    "            print('{} Loss: {:.2f} Acc: {:.1f}'.format(phase, epoch_loss, epoch_acc))\n",
    "           \n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_idx = epoch\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#                 best_model_wts = copy.deepcopy(model.module.state_dict())\n",
    "                print('==> best model saved - %d / %.1f'%(best_idx, best_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best valid Acc: %d - %.1f' %(best_idx, best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), 'ic_model.pt')\n",
    "    print('model saved')\n",
    "    return model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model.parameters(), \n",
    "                         lr = 0.05,\n",
    "                         momentum=0.9,\n",
    "                         weight_decay=1e-4)\n",
    "\n",
    "lmbda = lambda epoch: 0.98739\n",
    "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, best_idx, best_acc, train_loss, train_acc, valid_loss, valid_acc = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결과 그래프 그리기\n",
    "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(train_acc, 'b-')\n",
    "ax1.plot(valid_acc, 'r-')\n",
    "plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
    "ax1.set_xlabel('epoch')\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('acc', color='k')\n",
    "ax1.tick_params('y', colors='k')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train_loss, 'g-')\n",
    "ax2.plot(valid_loss, 'k-')\n",
    "plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
    "ax2.set_ylabel('loss', color='k')\n",
    "ax2.tick_params('y', colors='k')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_visualize_model(model, phase = 'test', num_images=4):\n",
    "    # phase = 'train', 'valid', 'test'\n",
    "    \n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)  # batch의 평균 loss 출력\n",
    "\n",
    "            running_loss    += loss.item() * inputs.size(0)\n",
    "            running_corrects+= torch.sum(preds == labels.data)\n",
    "            num_cnt += inputs.size(0)  # batch size\n",
    "\n",
    "    #         if i == 2: break\n",
    "\n",
    "        test_loss = running_loss / num_cnt\n",
    "        test_acc  = running_corrects.double() / num_cnt       \n",
    "        print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))\n",
    "\n",
    "    # 예시 그림 plot\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)        \n",
    "\n",
    "            # 예시 그림 plot\n",
    "            for j in range(1, num_images+1):\n",
    "                ax = plt.subplot(num_images//2, 2, j)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('%s : %s -> %s'%(\n",
    "                    'True' if class_names[str(labels[j].cpu().numpy())]==class_names[str(preds[j].cpu().numpy())] else 'False',\n",
    "                    class_names[str(labels[j].cpu().numpy())], class_names[str(preds[j].cpu().numpy())]))\n",
    "                imshow(inputs.cpu().data[j])          \n",
    "            if i == 0 : break\n",
    "\n",
    "\n",
    "    model.train(mode=was_training);  # 다시 train모드로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## TEST!\n",
    "    test_and_visualize_model(model, phase = 'test')"
   ]
  }
 ]
}